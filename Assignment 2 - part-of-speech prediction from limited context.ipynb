{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4045a47f",
   "metadata": {},
   "source": [
    "# Assignment 2 - part-of-speech prediction from limited context\n",
    "\n",
    "In this assignment, you will train classifiers that attempt, within a window of five words, to make a binary prediction about whether the third word belongs to a given part of speech (noun, verb, adjective, adverb), but using very limited information -- that is, the last two letters of the first, second, fourth, and fifth word of the sequence, and no information whatsoever directly from the third word itself.  You will strip out all punctuation (using the NLTK `WordPunctTokenizer`), lowercase, and remove stop words (using the NLTK English stop words list).\n",
    "\n",
    "In other words, you will predict over samples that have two classes, P and not-P, where P is the selected part of speech to classify.  For example, from the sentence, \"The quick brown fox jumped over the lazy dog.\", we can select the following 5-word windows without stop words, \"brown fox jumped lazy dog\" and \"quick brown fox jumped lazy\".  If we select verbs as the part-of-speech we are classifying over, we get the instances <(wn,ox,zy,og),1>, since \"jumped\" is a verb, but <(ck,wn,ed,zy),0> because \"fox\" in that context is not.\n",
    "\n",
    "This means that you will need to take into account the position of the last-two-letter feature:  \"zy\" as the fourth word's last two letters is different from \"zy\" as the fifth word's last two letters.  They are two features, say, `zy_4` and `zy_5`.\n",
    "\n",
    "This will likely not actually work.  But it might!\n",
    "\n",
    "You will create training and testing samples according to this procedure, and you will build a data structure that can be fed to a support vector machine (SVM) classifier.  You will train the classifier on the training data and evaluate it on the testing data. \n",
    "\n",
    "The work will be done in a .py module file in the same folder as this notebook.  **No modifications to this notebook will be graded.** We will run your module using this notebook or one we modify that you won't see in order to test your code.\n",
    "\n",
    "The file you must create and add to the github repo is `mycode.py`, which will be imported here.  You can create your own notebooks or scripts to test it.  You can put any number of your own helper functions and also put optional parameters on any of the python functions mentioned here. You should also create a Markdown file, `notes.md`, to keep any **concise** notes and remarks about the assignment.  The code must run on mltgpu.\n",
    "\n",
    "**This assignment is due Monday, 2022 March 7, at 23:59. There are 33 points and 5 bonus points.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6be47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61facb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mycode as mc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129e40ca",
   "metadata": {},
   "source": [
    "## Part 0 - preparation (2 points)\n",
    "\n",
    "Fork this repository and create and add `mycode.py` and `notes.md`. \n",
    "\n",
    "## Part 1 - obtaining the text (3 points)\n",
    "\n",
    "You will randomly select the given number of lines from the gzipped file we give you (so you will have to figure out how to access gzipped text files).  Explain how you implemented the random selection in `notes.md`. When we run it, it should give a new sample every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "612f08f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[b'PMIF provides cover against loan defaulting, insuring loans over their full term on a commercially viable basis.\\n',\n",
       " b'On Thursday, 20 February, a conference link-up was arranged with representatives of the United Nations Development Programme, the secretariat of the Permanent Forum in DESA and the World Bank office in New York.\\n',\n",
       " b'The provisions of draft article 14 were intended to fill in the gaps where the intention of the parties remained unclear.\\n',\n",
       " b'Report of the Special Rapporteur on adequate housing as a component\\n',\n",
       " b'For the \"second wave\" of countries behind the potential graduation cases (i.e. countries demonstrating some structural progress, but not yet foreseeing graduation in the near future), country-specific packages of measures could be formulated in the light of an analysis of structural disadvantages as measured under the LDC criteria.\\n',\n",
       " b'Its outbreak and spread pose a threat to public health undertakings.\\n',\n",
       " b'The Council elected Jordan for a term beginning on the date of election and expiring on 31 December 2004.\\n',\n",
       " b\"464. Anyone evading a statutory obligation to provide maintenance for a child as a result of which the child's necessities of life are at risk or would be at risk without the help of others is liable to prosecution for breach of the obligation to provide maintenance.\\n\",\n",
       " b'\"Even as we speak the bones of our little ones are forming; their blood is coursing through their veins; their hearts are beating; our children are growing and they can no longer wait.\\n',\n",
       " b\"A national centre for training in public health care was currently in operation at the Social Security Institute's Gynaecology and Obstetrics Hospital, and 60 doctors and 48 nurses from 18 hospitals had been trained in voluntary contraceptive surgery.\\n\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sampled_lines = mc.sample_lines(\"/scratch/UN-english.txt.gz\", lines=100000)\n",
    "\n",
    "print(len(sampled_lines))\n",
    "sampled_lines[40000:40010]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94a339",
   "metadata": {},
   "source": [
    "## Part 2 - creating the samples (7 points)\n",
    "\n",
    "From the sampled lines, you will then randomly create the five-word samples.\n",
    "\n",
    "You will tokenize the sentences and apply POS-tagging to them -- you need to do this before you create the samples, since POS-tagging needs context. You will then remove stop words and punctuation and lowercase the remainder.  Next, you will randomly, over the entire set of sentences, choose samples of five words in sequence, up to a certain limit.  You find the last two characters of the first, second, fourth, and fifth words, and create the type of structure specified up in the introduction to this assignment for each sample. The exact representation is up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "192b9d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            word  POS\n",
       " 0           pmif  NNP\n",
       " 1       provides  VBZ\n",
       " 2          cover   NN\n",
       " 3           loan   NN\n",
       " 4     defaulting   NN\n",
       " 5       insuring  VBG\n",
       " 6          loans  NNS\n",
       " 7           full   JJ\n",
       " 8           term   NN\n",
       " 9   commercially   RB\n",
       " 10        viable   JJ\n",
       " 11         basis   NN,\n",
       "                word  POS\n",
       " 0          thursday  NNP\n",
       " 1          february  NNP\n",
       " 2        conference   NN\n",
       " 3              link   NN\n",
       " 4          arranged  VBN\n",
       " 5   representatives  NNS\n",
       " 6            united  NNP\n",
       " 7           nations  NNP\n",
       " 8       development  NNP\n",
       " 9         programme  NNP\n",
       " 10      secretariat   NN\n",
       " 11        permanent  NNP\n",
       " 12            forum  NNP\n",
       " 13             desa  NNP\n",
       " 14            world  NNP\n",
       " 15             bank  NNP\n",
       " 16           office   NN\n",
       " 17              new  NNP\n",
       " 18             york  NNP,\n",
       "          word  POS\n",
       " 0  provisions  NNS\n",
       " 1       draft   NN\n",
       " 2     article   NN\n",
       " 3    intended  VBN\n",
       " 4        fill   VB\n",
       " 5        gaps  NNS\n",
       " 6   intention   NN\n",
       " 7     parties  NNS\n",
       " 8    remained  VBD\n",
       " 9     unclear   JJ,\n",
       "          word  POS\n",
       " 0      report   NN\n",
       " 1     special   JJ\n",
       " 2  rapporteur  NNP\n",
       " 3    adequate   JJ\n",
       " 4     housing   NN\n",
       " 5   component   NN,\n",
       "              word  POS\n",
       " 0          second   JJ\n",
       " 1            wave   NN\n",
       " 2       countries  NNS\n",
       " 3          behind   IN\n",
       " 4       potential   JJ\n",
       " 5      graduation   NN\n",
       " 6           cases  NNS\n",
       " 7               e   NN\n",
       " 8       countries  NNS\n",
       " 9   demonstrating  VBG\n",
       " 10     structural   JJ\n",
       " 11       progress   NN\n",
       " 12            yet   RB\n",
       " 13     foreseeing  VBG\n",
       " 14     graduation   NN\n",
       " 15           near   JJ\n",
       " 16         future   NN\n",
       " 17        country   NN\n",
       " 18       specific   JJ\n",
       " 19       packages  NNS\n",
       " 20       measures  NNS\n",
       " 21          could   MD\n",
       " 22     formulated  VBN\n",
       " 23          light   NN\n",
       " 24       analysis   NN\n",
       " 25     structural   JJ\n",
       " 26  disadvantages  NNS\n",
       " 27       measured  VBN\n",
       " 28            ldc  NNP\n",
       " 29       criteria  NNS,\n",
       "            word  POS\n",
       " 0      outbreak   NN\n",
       " 1        spread   NN\n",
       " 2          pose  VBP\n",
       " 3        threat   NN\n",
       " 4        public   JJ\n",
       " 5        health   NN\n",
       " 6  undertakings  NNS,\n",
       "         word  POS\n",
       " 0    council  NNP\n",
       " 1    elected  VBD\n",
       " 2     jordan  NNP\n",
       " 3       term   NN\n",
       " 4  beginning  VBG\n",
       " 5       date   NN\n",
       " 6   election   NN\n",
       " 7   expiring  VBG\n",
       " 8   december  NNP,\n",
       "            word  POS\n",
       " 0        anyone   NN\n",
       " 1       evading  VBG\n",
       " 2     statutory   JJ\n",
       " 3    obligation   NN\n",
       " 4       provide   VB\n",
       " 5   maintenance   NN\n",
       " 6         child   NN\n",
       " 7        result   NN\n",
       " 8         child   NN\n",
       " 9   necessities  NNS\n",
       " 10         life   NN\n",
       " 11         risk   NN\n",
       " 12        would   MD\n",
       " 13         risk   NN\n",
       " 14      without   IN\n",
       " 15         help   NN\n",
       " 16       others  NNS\n",
       " 17       liable   JJ\n",
       " 18  prosecution   NN\n",
       " 19       breach   NN\n",
       " 20   obligation   NN\n",
       " 21      provide   VB\n",
       " 22  maintenance   NN,\n",
       "         word  POS\n",
       " 0       even   RB\n",
       " 1      speak  VBP\n",
       " 2      bones  NNS\n",
       " 3     little   JJ\n",
       " 4       ones  NNS\n",
       " 5    forming  VBG\n",
       " 6      blood   NN\n",
       " 7   coursing  VBG\n",
       " 8      veins  NNS\n",
       " 9     hearts  NNS\n",
       " 10   beating  VBG\n",
       " 11  children  NNS\n",
       " 12   growing  VBG\n",
       " 13    longer  RBR\n",
       " 14      wait   VB,\n",
       "              word  POS\n",
       " 0        national   JJ\n",
       " 1          centre   NN\n",
       " 2        training  VBG\n",
       " 3          public   JJ\n",
       " 4          health   NN\n",
       " 5            care   NN\n",
       " 6       currently   RB\n",
       " 7       operation   NN\n",
       " 8          social  NNP\n",
       " 9        security  NNP\n",
       " 10      institute  NNP\n",
       " 11    gynaecology  NNP\n",
       " 12     obstetrics  NNP\n",
       " 13       hospital  NNP\n",
       " 14        doctors  NNS\n",
       " 15         nurses  NNS\n",
       " 16      hospitals  NNS\n",
       " 17        trained  VBN\n",
       " 18      voluntary   JJ\n",
       " 19  contraceptive   NN\n",
       " 20        surgery   NN]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_sentences = mc.process_sentences(sampled_lines)\n",
    "processed_sentences[40000:40010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670bd928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[            word POS\n",
      "1           like  VB\n",
      "2           take  VB\n",
      "3    opportunity  NN\n",
      "4          thank  VB\n",
      "5  participation  NN,             word  POS\n",
      "1         growth   NN\n",
      "2        however   RB\n",
      "3         united  NNP\n",
      "4        nations  NNP\n",
      "5  organizations  NNS,            word  POS\n",
      "21       nodule   NN\n",
      "22     province   NN\n",
      "23          key   JJ\n",
      "24   components  NNS\n",
      "25  polychaetes  NNS,        word  POS\n",
      "0      orms  NNS\n",
      "1  violence   NN\n",
      "2     women  NNS\n",
      "3     girls  NNS\n",
      "4   defined  VBN,           word  POS\n",
      "3     document   NN\n",
      "4     provides  VBZ\n",
      "5   additional   JJ\n",
      "6  information   NN\n",
      "7   comparison   NN,         word  POS\n",
      "3   strategy   NN\n",
      "4      focus   VB\n",
      "5     solely   RB\n",
      "6  promoting  VBG\n",
      "7       cost   NN,          word  POS\n",
      "1     forward   RB\n",
      "2     address   VB\n",
      "3  challenges  NNS\n",
      "4     consult   VB\n",
      "5     friends  NNS,            word  POS\n",
      "1      possible   JJ\n",
      "2  consequences  NNS\n",
      "3           use   NN\n",
      "4       nuclear   JJ\n",
      "5       weapons  NNS,       word  POS\n",
      "0       un  NNP\n",
      "1  replace   VB\n",
      "2   column   NN\n",
      "3   delete   JJ\n",
      "4   column   NN,         word  POS\n",
      "2  secretary  NNP\n",
      "3    general  NNP\n",
      "4      posed  VBD\n",
      "5       hard   JJ\n",
      "6  questions  NNS]\n"
     ]
    }
   ],
   "source": [
    "all_samples = mc.create_samples(processed_sentences, samples=50000)\n",
    "\n",
    "print(all_samples[25000:25010])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6be6d",
   "metadata": {},
   "source": [
    "## Part 3 - convert the samples into a Pandas DataFrame (10 points)\n",
    "\n",
    "Here, you will take the samples and create a table whose columns are the features and the class and whose rows are the samples.  All the features and the class will be binary.  Note that there may be many columns, in the hundreds or thousands depending on the diversity of the final two consonants of the non-stop-words in the dataset, but the sum of all rows will be five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f9fbd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(1, ab)</th>\n",
       "      <th>(1, ac)</th>\n",
       "      <th>(1, ad)</th>\n",
       "      <th>(1, ae)</th>\n",
       "      <th>(1, af)</th>\n",
       "      <th>(1, ag)</th>\n",
       "      <th>(1, ah)</th>\n",
       "      <th>(1, ai)</th>\n",
       "      <th>(1, ak)</th>\n",
       "      <th>(1, al)</th>\n",
       "      <th>...</th>\n",
       "      <th>(4, yi)</th>\n",
       "      <th>(4, ym)</th>\n",
       "      <th>(4, yn)</th>\n",
       "      <th>(4, yp)</th>\n",
       "      <th>(4, ys)</th>\n",
       "      <th>(4, yz)</th>\n",
       "      <th>(4, z)</th>\n",
       "      <th>(4, za)</th>\n",
       "      <th>(4, ze)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25004</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25005</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25006</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25007</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25008</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25009</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1589 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       (1, ab)  (1, ac)  (1, ad)  (1, ae)  (1, af)  (1, ag)  (1, ah)  (1, ai)  \\\n",
       "25000        0        0        0        0        0        0        0        0   \n",
       "25001        0        0        0        0        0        0        0        0   \n",
       "25002        0        0        0        0        0        0        0        0   \n",
       "25003        0        0        0        0        0        0        0        0   \n",
       "25004        0        0        0        0        0        0        0        0   \n",
       "25005        0        0        0        0        0        0        0        0   \n",
       "25006        0        0        0        0        0        0        0        0   \n",
       "25007        0        0        0        0        0        0        0        0   \n",
       "25008        0        0        0        0        0        0        0        0   \n",
       "25009        0        0        0        0        0        0        0        0   \n",
       "\n",
       "       (1, ak)  (1, al)  ...  (4, yi)  (4, ym)  (4, yn)  (4, yp)  (4, ys)  \\\n",
       "25000        0        0  ...        0        0        0        0        0   \n",
       "25001        0        0  ...        0        0        0        0        0   \n",
       "25002        0        0  ...        0        0        0        0        0   \n",
       "25003        0        0  ...        0        0        0        0        0   \n",
       "25004        0        0  ...        0        0        0        0        0   \n",
       "25005        0        0  ...        0        0        0        0        0   \n",
       "25006        0        0  ...        0        0        0        0        0   \n",
       "25007        0        0  ...        0        0        0        0        0   \n",
       "25008        0        0  ...        0        0        0        0        0   \n",
       "25009        0        0  ...        0        0        0        0        0   \n",
       "\n",
       "       (4, yz)  (4, z)  (4, za)  (4, ze)  target  \n",
       "25000        0       0        0        0       1  \n",
       "25001        0       0        0        0       0  \n",
       "25002        0       0        0        0       0  \n",
       "25003        0       0        0        0       0  \n",
       "25004        0       0        0        0       0  \n",
       "25005        0       0        0        0       0  \n",
       "25006        0       0        0        0       0  \n",
       "25007        0       0        0        0       1  \n",
       "25008        0       0        0        0       1  \n",
       "25009        0       0        0        0       0  \n",
       "\n",
       "[10 rows x 1589 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf = mc.create_df(all_samples)\n",
    "fulldf[25000:25010]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34b87ed",
   "metadata": {},
   "source": [
    "## Part 4 - extract training and testing sets (3 points)\n",
    "\n",
    "Here, you will create the training and testing datasets in order to train the model.  This will be based on a test percentage.  Round up if the percentage does not divide evenly into the sample size.  You will need to separate the class column into the y-values for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc332791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 40000, 10000, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = mc.split_samples(fulldf, test_percent=20)\n",
    "len(train_X), len(train_y), len(test_X), len(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160744cb",
   "metadata": {},
   "source": [
    "## Part 5 - train models (3 points)\n",
    "\n",
    "You will then train and return two support vector machine (SVM) models using the sklearn SVC class.  You should allow a choice between linear and radial basis function kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42eedaad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SVC(kernel='linear'), SVC())"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linear = mc.train(train_X, train_y, kernel='linear')\n",
    "model_rbf = mc.train(train_X, train_y, kernel=\"rbf\")\n",
    "model_linear, model_rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0d4664",
   "metadata": {},
   "source": [
    "## Part 6 - evaluate the models (5 points)\n",
    "\n",
    "You will calculate and print precision, recall, and F-measure for the models on the test data. In `notes.md`, write down your comparison of these simple measures on the two models and any thoughts you might have on what they mean. (It could be very short, and since the samples do not stay stable between runs, you can save the evaluation scores in `notes.md` too.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abcfbcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.72556126, 0.79104478]),\n",
       " array([0.99806121, 0.01907161]),\n",
       " array([0.84027049, 0.03724526]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mc.eval_model(model_rbf, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5250a03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.7238269 , 0.40601504]),\n",
       " array([0.98905969, 0.01943145]),\n",
       " array([0.83590824, 0.03708791]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.eval_model(model_linear, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa9b71e",
   "metadata": {},
   "source": [
    "## Part Bonus - try another sort of model from sklearn (5 points)\n",
    "\n",
    "Write a separate, command-line script (not a notebook) uses `mycode.py` to do all of the above, except that it trains a non-SVM classifier model.  Any non-trivial model available in sklearn will do. Explain how to run your code and the results of your own evaluation in `notes.md`, including any observations or opinions you may have on the classifier method you used in comparison to SVM.\n",
    "\n",
    "## Submission\n",
    "\n",
    "Push to your fork of the GitHub repository (which must be made public) and submit the URL of your repository in Canvas.  You can submit this notebook with the output from your run, as long as you do not modify the code or text in it without permission from us.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b52d1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.82564103, 0.28210198]),\n",
       " array([0.04459216, 0.97553077]),\n",
       " array([0.08461437, 0.4376463 ]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.eval_Naive_Bayes(train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24994b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
